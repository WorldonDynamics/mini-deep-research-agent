>>>>>>> 270e952a2de0a6d81c3475cfc1d86291627884d4
<!-- Copilot / AI contributor instructions -->
# Copilot / AI contributor instructions

These notes give concise, actionable context for AI contributors working in this repository and the `mini-deep-research-agent` subproject.

Repository focus
- **Summary:** A lightweight Python toolkit for loading research paper datasets, computing sentence-transformer embeddings, performing semantic search, and summarizing top results.

Primary entry points
- **Demo runner:** `mini-deep-research-agent/src/main.py` — example runner that performs queries and writes `output/multi_query_results.json`.
- **Core utilities:** `mini-deep-research-agent/src/utils.py` — functions: `load_data`, `embed_texts` (cache-first), `semantic_search`, and `summarize_papers`.

Important files & paths
- **Raw data:** `Data/raw/dummy_papers.csv` (example dataset used by demos and tests).
- **Embeddings cache:** `Data/processed/embeddings.pkl` — generated by `embed_texts`. The code uses a cache-first flow; remove or version this file when changing the embedding model or format.
- **Output:** `output/multi_query_results.json` (scripts create directories as needed). The repo `.gitignore` excludes `output/` and `Data/processed/`.

Key patterns and constraints (preserve unless intentionally changed)
- **Single global model instance:** A `SentenceTransformer('all-MiniLM-L6-v2')` is created in `utils.py` at import time to avoid repeated loads. If you switch to lazy-loading, update instructions and tests accordingly.
- **Cache-first embeddings:** `embed_texts` checks for an existing cache and returns cached embeddings when present. If you change model or embedding shape, clear or version the cache to avoid mixing embeddings.
- **Relative paths & BASE_DIR:** Code uses relative paths (e.g., `../Data/raw/dummy_papers.csv`) and sometimes a `BASE_DIR` helper. Keep these patterns so scripts remain runnable from the repo or subproject root.
- **Data schema assumptions:** The code expects `title`, `abstract`, and `authors` columns. Update `semantic_search` and `summarize_papers` if you change the schema.

Developer workflows & examples (PowerShell)
- **Install deps:**

```powershell
pip install -r requirements.txt
```

- **Run demo (from repository root or `mini-deep-research-agent`):**

```powershell
python mini-deep-research-agent/src/main.py
# or, from the subfolder:
python src/main.py
```

- **Force embeddings refresh:**

```powershell
# Remove the cache, then re-run the demo
Remove-Item Data/processed/embeddings.pkl
python src/main.py
```

Testing & CI notes
- Avoid importing `sentence_transformers` at test-time: because the model loads on import, unit tests should mock the model or `embed_texts` (or introduce a lazy-load wrapper) to keep tests fast and deterministic.

Change guidance (what to update when modifying behavior)
- **Changing the embedding model:** Update `model = SentenceTransformer(...)` in `mini-deep-research-agent/src/utils.py`, update `requirements.txt` if necessary (e.g., add `torch`), and clear/version `Data/processed/embeddings.pkl`.
- **Changing data schema:** Update `semantic_search` composition (it currently concatenates title + ". " + abstract) and adjust any code/tests that assume `title`/`abstract`/`authors` exist.

Where to look
- `mini-deep-research-agent/src/utils.py` — embedding, cache patterns, semantic search, summarization.
- `mini-deep-research-agent/src/main.py` — example runner and output behavior.
- `Data/raw/dummy_papers.csv` — sample dataset and fields for tests/mocks.

Optional follow-ups I can help with
- Add a small unit-test skeleton that mocks the embedding model for CI.
- Add a short `AGENT.md` or `CONTRIBUTING.md` with step-by-step developer flows.

If you'd like, I can now run the tests or update a README to reference these instructions. Tell me what you'd like next.
