<!-- Top-level Copilot instructions for Deep-Research-Agent -->
# Copilot / AI contributor instructions (repository root)

This file gives concise, actionable context for AI contributors working across the repository.

**Project Summary:**: A lightweight Python toolkit for loading research paper datasets, computing sentence-transformer embeddings, performing semantic search, and summarizing top results.

**Primary entry points to edit or run:**
- `mini-deep-research-agent/src/main.py` — example runner (demo queries, writes `output/multi_query_results.json`).
- `mini-deep-research-agent/src/utils.py` — core utilities: `load_data`, `embed_texts` (cache), `semantic_search`, and `summarize_papers`.

**Data layout & caches:**
- Raw sample dataset: `Data/raw/dummy_papers.csv` — use this to design tests and mocks.
- Embeddings cache: `Data/processed/embeddings.pkl` — generated by `embed_texts`. Respect cache-first behavior when running locally and CI.
- Output folder: `output/` (scripts create it as needed). The repository `.gitignore` already excludes `output/` and `Data/processed/`.

**Key patterns and constraints (do not change without reason):**
- Model instantiation: A `SentenceTransformer` model is loaded at module import time in `utils.py`. To keep quick demo runs, preserve the single global model instance, or introduce lazy-loading and update instructions.
- Embeddings cache-first: `embed_texts` checks for a cache file. If you change the model or embedding format, clear or version the cache to avoid mixing embeddings.
- Data columns: code assumes `title`, `abstract`, and `authors` columns exist. Update `semantic_search` and `summarize_papers` if the schema changes.
- Relative paths: scripts use relative paths (e.g., `../Data/raw/dummy_papers.csv`) and sometimes compute `BASE_DIR`. Keep these patterns consistent so scripts run from the repo or `mini-deep-research-agent` subfolder.

**Developer workflows & commands**
- Install dependencies (PowerShell):

```
pip install -r requirements.txt
```

- Run the demo (from repository root or `mini-deep-research-agent`):

```
python mini-deep-research-agent/src/main.py
```

- Force embeddings refresh:

```
Remove `Data/processed/embeddings.pkl` then re-run the main script.
```

**Testing & CI notes**
- Avoid importing `sentence_transformers` at test-time. Because the model loads on import, unit tests should mock the model and `embed_texts` or the `model.encode` calls. Consider adding a lazy-load wrapper if you need many fast unit tests.

**Change guidance examples**
- Changing the embedding model: update `mini-deep-research-agent/src/utils.py` (model line) and `requirements.txt` as needed; clear `Data/processed/embeddings.pkl`.
- Changing data schema: update `semantic_search` composition and `summarize_papers` to match new column names and adjust unit tests.

**Where to look for context**
- `mini-deep-research-agent/src/utils.py` — canonical examples for caching, embeddings, and search.
- `mini-deep-research-agent/src/main.py` — example CLI/demo runner and output save behavior.
- `Data/raw/dummy_papers.csv` — example dataset and fields.

If you want, I can also:
- Add a minimal unit-test skeleton that mocks the embedding model for CI.
- Add a small `CONTRIBUTING.md` or `AGENT.md` with step-by-step developer flows.
